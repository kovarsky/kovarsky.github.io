---
title: "Neural Machine Translation"
date: 2024-12-25
draft: false
tags: ["ML", "NMT", "transformers"]
---

## Project Overview

I worked on one of the first production neural machine translation systems.

### Architecture

We used encoder-decoder transformers with attention mechanisms.

### Results

- 30% improvement over statistical MT
- Real-time translation capabilities
- Deployed to production serving millions of requests

## Key Learnings

Working on NMT taught me about:
1. Attention mechanisms
2. Sequence-to-sequence models
3. Production ML systems


